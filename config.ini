[FilePaths]
zero_shot_prompting_result_file = ./results/zero_shot_prompting.json
prompt_template = ./data/raw/prompt_template.txt
test_data_file = ./data/processed/test_processed_data_100.json
prepared_data_file = ./data/processed/test_processed_data_100.json
zero_shot_results_file = ./results/zero_shot_prompting.json

[Token]
llamaapi = LL-toLj4vcjSC82cwlgF0yf0o5sUs8tTj8tPhbABsKMb1c74TnQud7bJbcFozHTu00n
groqapi = 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

[Model]
model_1 = llama3-8b-8192
model_2 = llama3-70b-8192
model_3 = mixtral-8x7b-32768

[Templates]
model_1_prompt_templates = data/raw/prompt_template.txt 
model_2_prompt_templates = data/raw/prompt_template.txt
model_3_prompt_templates = data/raw/prompt_template.txt

[Flags]
use_api = True
api_type = groq  

[Parameters]
max_length_input = 4000
max_output_length = 50